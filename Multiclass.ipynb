{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset shape: (1720991, 96)\n",
      "Label distribution:\n",
      " Label\n",
      "Benign                                    1206738\n",
      "Portscan                                   159059\n",
      "DoS Hulk                                   158468\n",
      "DDoS                                        95144\n",
      "Infiltration - Portscan                     68620\n",
      "DoS GoldenEye                                7567\n",
      "Botnet - Attempted                           4064\n",
      "FTP-Patator                                  3972\n",
      "DoS Slowloris                                3859\n",
      "DoS Slowhttptest - Attempted                 3368\n",
      "SSH-Patator                                  2961\n",
      "DoS Slowloris - Attempted                    1847\n",
      "DoS Slowhttptest                             1740\n",
      "Web Attack - Brute Force - Attempted         1292\n",
      "Botnet                                        736\n",
      "Web Attack - XSS - Attempted                  655\n",
      "DoS Hulk - Attempted                          581\n",
      "DoS GoldenEye - Attempted                      80\n",
      "Web Attack - Brute Force                       73\n",
      "Infiltration - Attempted                       45\n",
      "Infiltration                                   36\n",
      "SSH-Patator - Attempted                        27\n",
      "Web Attack - XSS                               18\n",
      "Web Attack - SQL Injection                     13\n",
      "FTP-Patator - Attempted                        12\n",
      "Heartbleed                                     11\n",
      "Web Attack - SQL Injection - Attempted          5\n",
      "Name: count, dtype: int64\n",
      "Encoded classes: ['Benign', 'Botnet', 'Botnet - Attempted', 'DDoS', 'DoS GoldenEye', 'DoS GoldenEye - Attempted', 'DoS Hulk', 'DoS Hulk - Attempted', 'DoS Slowhttptest', 'DoS Slowhttptest - Attempted', 'DoS Slowloris', 'DoS Slowloris - Attempted', 'FTP-Patator', 'FTP-Patator - Attempted', 'Heartbleed', 'Infiltration', 'Infiltration - Attempted', 'Infiltration - Portscan', 'Portscan', 'SSH-Patator', 'SSH-Patator - Attempted', 'Web Attack - Brute Force', 'Web Attack - Brute Force - Attempted', 'Web Attack - SQL Injection', 'Web Attack - SQL Injection - Attempted', 'Web Attack - XSS', 'Web Attack - XSS - Attempted']\n",
      "Original training set shape: Counter({np.int64(0): 844716, np.int64(18): 111341, np.int64(6): 110928, np.int64(3): 66601, np.int64(17): 48034, np.int64(4): 5297, np.int64(2): 2845, np.int64(12): 2780, np.int64(10): 2701, np.int64(9): 2358, np.int64(19): 2073, np.int64(11): 1293, np.int64(8): 1218, np.int64(22): 904, np.int64(1): 515, np.int64(26): 458, np.int64(7): 407, np.int64(5): 56, np.int64(21): 51, np.int64(16): 31, np.int64(15): 25, np.int64(20): 19, np.int64(25): 13, np.int64(23): 9, np.int64(13): 8, np.int64(14): 8, np.int64(24): 4})\n",
      "Training set label distribution: Counter({np.int64(0): 844716, np.int64(18): 111341, np.int64(6): 110928, np.int64(3): 66601, np.int64(17): 48034, np.int64(4): 5297, np.int64(2): 2845, np.int64(12): 2780, np.int64(10): 2701, np.int64(9): 2358, np.int64(19): 2073, np.int64(11): 1293, np.int64(8): 1218, np.int64(22): 904, np.int64(1): 515, np.int64(26): 458, np.int64(7): 407, np.int64(5): 56, np.int64(21): 51, np.int64(16): 31, np.int64(15): 25, np.int64(20): 19, np.int64(25): 13, np.int64(23): 9, np.int64(13): 8, np.int64(14): 8, np.int64(24): 4})\n",
      "Smallest class count in training: 4\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Load and combine datasets\n",
    "tuesday = pd.read_csv('tuesday_plus_cleaned.csv')\n",
    "wednesday = pd.read_csv('wednesday_plus_cleaned.csv')\n",
    "thursday = pd.read_csv('thursday_plus_cleaned.csv')\n",
    "friday = pd.read_csv('friday_plus_cleaned.csv')\n",
    "\n",
    "df = pd.concat([tuesday, wednesday, thursday, friday], ignore_index=True)\n",
    "\n",
    "print(f\"Combined dataset shape: {df.shape}\")\n",
    "print(\"Label distribution:\\n\", df['Label'].value_counts())\n",
    "\n",
    "# Step 2: Prepare features and target\n",
    "# Drop columns that are identifiers or non-feature columns if any (adjust as needed)\n",
    "# For example, if columns like 'Flow ID', 'Timestamp' etc. exist, drop them here\n",
    "leak_columns = ['Flow ID', 'Timestamp', 'Source IP', 'Destination IP']  # adjust if needed\n",
    "for col in leak_columns:\n",
    "    if col in df.columns:\n",
    "        df = df.drop(columns=[col])\n",
    "\n",
    "X = df.drop(columns=['Label'])\n",
    "y = df['Label']\n",
    "\n",
    "# Step 3: Encode target labels (multi-class)\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "print(f\"Encoded classes: {list(le.classes_)}\")\n",
    "\n",
    "# Step 4: Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_enc, test_size=0.3, random_state=42, stratify=y_enc\n",
    ")\n",
    "\n",
    "print(\"Original training set shape:\", Counter(y_train))\n",
    "\n",
    "from collections import Counter\n",
    "print(\"Training set label distribution:\", Counter(y_train))\n",
    "\n",
    "# Find smallest class count in training\n",
    "min_class_count = min(Counter(y_train).values())\n",
    "print(f\"Smallest class count in training: {min_class_count}\")\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Use fewer neighbors to match your data\n",
    "smote = SMOTE(random_state=42, k_neighbors=2)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Step 5: Handle imbalance with SMOTE on training data only\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Resampled training set shape:\", Counter(y_train_res))\n",
    "\n",
    "# Step 6: Train Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Step 7: Predict on test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Step 8: Evaluation\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "# Confusion matrix plot\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Multi-class Classification')\n",
    "plt.show()\n",
    "\n",
    "# Step 9: Feature importance plot\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "features = X.columns\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x=importances[indices[:20]], y=features[indices[:20]], palette='viridis')\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
